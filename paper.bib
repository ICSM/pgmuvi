
@InProceedings{wilson:2013,
  title = 	 {Gaussian Process Kernels for Pattern Discovery and Extrapolation},
  author = 	 {Wilson, Andrew and Adams, Ryan},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {1067--1075},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {3},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/wilson13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/wilson13.html},
  abstract = 	 {Gaussian processes are rich distributions over functions, which provide a Bayesian nonparametric approach to smoothing and interpolation.  We introduce simple closed form kernels that can be used with Gaussian processes to discover patterns and enable extrapolation.  These kernels are derived by modelling a spectral density – the Fourier transform of a kernel – with a Gaussian mixture.  The proposed kernels support a broad class of stationary covariances, but Gaussian process inference remains simple and analytic.  We demonstrate the proposed kernels by discovering patterns and performing long range extrapolation on synthetic examples, as well as atmospheric CO2 trends and airline passenger data.  We also show that it is possible to reconstruct several popular standard covariances within our framework.}
}

@article{gardner2018gpytorch,
  title={Gpytorch: Blackbox matrix-matrix gaussian process inference with gpu acceleration},
  author={Gardner, Jacob and Pleiss, Geoff and Weinberger, Kilian Q and Bindel, David and Wilson, Andrew G},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{wilson2015kernel,
  title={Kernel interpolation for scalable structured Gaussian processes (KISS-GP)},
  author={Wilson, Andrew and Nickisch, Hannes},
  booktitle={International conference on machine learning},
  pages={1775--1784},
  year={2015},
  organization={PMLR}
}

@article{hensman2013gaussian,
  title={Gaussian processes for big data},
  author={Hensman, James and Fusi, Nicolo and Lawrence, Neil D},
  journal={arXiv preprint arXiv:1309.6835},
  year={2013}
}

@inproceedings{wu2022variational,
  title={Variational nearest neighbor Gaussian process},
  author={Wu, Luhuan and Pleiss, Geoff and Cunningham, John P},
  booktitle={International Conference on Machine Learning},
  pages={24114--24130},
  year={2022},
  organization={PMLR}
}

@article{celerite1,
   author = {{Foreman-Mackey}, D. and {Agol}, E. and {Ambikasaran}, S. and
            {Angus}, R.},
    title = "{Fast and Scalable Gaussian Process Modeling with Applications to
              Astronomical Time Series}",
  journal = {\aj},
     year = 2017,
    month = dec,
   volume = 154,
    pages = {220},
      doi = {10.3847/1538-3881/aa9332},
   adsurl = {http://adsabs.harvard.edu/abs/2017AJ....154..220F},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}
@article{celerite2,
   author = {{Foreman-Mackey}, D.},
    title = "{Scalable Backpropagation for Gaussian Processes using Celerite}",
  journal = {Research Notes of the American Astronomical Society},
     year = 2018,
    month = feb,
   volume = 2,
   number = 1,
    pages = {31},
      doi = {10.3847/2515-5172/aaaf6c},
   adsurl = {http://adsabs.harvard.edu/abs/2018RNAAS...2a..31F},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@software{tinygp,
  author       = {Foreman-Mackey, Daniel},
  title        = {{dfm/tinygp: The tiniest of Gaussian Process 
                   libraries}},
  month        = feb,
  year         = 2023,
  publisher    = {Zenodo},
  version      = {v0.2.4rc1},
  doi          = {10.5281/zenodo.7646759},
  url          = {https://doi.org/10.5281/zenodo.7646759}
}

@ARTICLE{ambikasaran2015george,
        author = {{Ambikasaran}, Sivaram and {Foreman-Mackey}, Daniel and {Greengard}, Leslie and {Hogg}, David W. and {O'Neil}, Michael},
         title = "{Fast Direct Methods for Gaussian Processes}",
       journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
      keywords = {Mathematics - Numerical Analysis, Astrophysics - Instrumentation and Methods for Astrophysics, Mathematics - Statistics Theory, Mathematics - Numerical Analysis, Astrophysics - Instrumentation and Methods for Astrophysics, Mathematics - Statistics Theory},
          year = 2015,
         month = jun,
        volume = {38},
         pages = {252},
           doi = {10.1109/TPAMI.2015.2448083},
 archivePrefix = {arXiv},
        eprint = {1403.6015},
  primaryClass = {math.NA},
        adsurl = {https://ui.adsabs.harvard.edu/abs/2015ITPAM..38..252A},
       adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{arev_2023_gps,
author = {Aigrain, Suzanne and Foreman-Mackey, Daniel},
title = {Gaussian Process Regression for Astronomical Time Series},
journal = {Annual Review of Astronomy and Astrophysics},
volume = {61},
number = {1},
pages = {null},
year = {2023},
doi = {10.1146/annurev-astro-052920-103508},

URL = { 
    
        https://doi.org/10.1146/annurev-astro-052920-103508
    
    

},
eprint = { 
    
        https://doi.org/10.1146/annurev-astro-052920-103508
    
    

}
,
    abstract = { The past two decades have seen a major expansion in the availability, size, and precision of time-domain data sets in astronomy. Owing to their unique combination of flexibility, mathematical simplicity, and comparative robustness, Gaussian processes (GPs) have emerged recently as the solution of choice to model stochastic signals in such data sets. In this review, we provide a brief introduction to the emergence of GPs in astronomy, present the underlying mathematical theory, and give practical advice considering the key modeling choices involved in GP regression. We then review applications of GPs to time-domain data sets in the astrophysical literature so far, from exoplanets to active galactic nuclei, showcasing the power and flexibility of the method. We provide worked examples using simulated data, with links to the source code; discuss the problem of computational cost and scalability; and give a snapshot of the current ecosystem of open source GP software packages. In summary: ▪GP regression is a conceptually simple but statistically principled and powerful tool for the analysis of astronomical time series. ▪It is already widely used in some subfields, such as exoplanets, and gaining traction in many others, such as optical transients. ▪Driven by further algorithmic and conceptual advances, we expect that GPs will continue to be an important tool for robust and interpretable time domain astronomy for many years to come. Expected final online publication date for the Annual Review of Astronomy and Astrophysics, Volume 61 is August 2023. Please see http://www.annualreviews.org/page/journal/pubdates for revised estimates. }
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{hoffman2014no,
  title={The No-U-Turn sampler: adaptively setting path lengths in Hamiltonian Monte Carlo.},
  author={Hoffman, Matthew D and Gelman, Andrew and others},
  journal={J. Mach. Learn. Res.},
  volume={15},
  number={1},
  pages={1593--1623},
  year={2014}
}